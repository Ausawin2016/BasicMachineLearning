{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"data/\", one_hot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None,784])\n",
    "#hidden\n",
    "hidden = 512\n",
    "W1 = tf.Variable(tf.truncated_normal([784,hidden],stddev=0.1))\n",
    "b1 = tf.Variable(tf.zeros([hidden]))\n",
    "#out layer\n",
    "W2 = tf.Variable(tf.truncated_normal([hidden,10],stddev=0.1))\n",
    "b2 = tf.Variable(tf.zeros([10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#model\n",
    "net = tf.nn.sigmoid(tf.matmul(X, W1) + b1)\n",
    "net1 = tf.matmul(net, W2) + b2\n",
    "Y = tf.nn.softmax(net1)\n",
    "Y_ = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#loss function\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=Y_, logits=net1))\n",
    "\n",
    "# % of correct answers found in batch\n",
    "is_correct = tf.equal(tf.argmax(Y,1), tf.argmax(Y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "\n",
    "# Create a summary to monitor cost tensor\n",
    "tf.summary.scalar('loss', cross_entropy)\n",
    "# Create a summary to monitor accuracy tensor\n",
    "tf.summary.scalar('accuracy', accuracy)\n",
    "#for weight\n",
    "with tf.name_scope('Weights'):\n",
    "    tf.summary.histogram(\"weight1\", W1)\n",
    "    tf.summary.histogram(\"weight2\", W2)\n",
    "    tf.summary.histogram(\"bias_1\", b1)\n",
    "    tf.summary.histogram(\"bias_2\", b2)\n",
    "\n",
    "summary_op = tf.summary.merge_all()\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer()\n",
    "train_step = optimizer.minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#create session\n",
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "#create summary op to write logs to Tensorboard\n",
    "train_summary_writer = tf.summary.FileWriter('logs/mlp_train', graph=sess.graph)\n",
    "test_summary_writer = tf.summary.FileWriter('logs/mlp_test', graph=sess.graph)\n",
    "\n",
    "for i in range(10000):\n",
    "    #load batch of images and correct answers\n",
    "    batch_X, batch_Y = mnist.train.next_batch(100)\n",
    "    train_data={X: batch_X, Y_: batch_Y}\n",
    "    #train    \n",
    "    _,summary = sess.run([train_step,summary_op], feed_dict=train_data)\n",
    "    # Write logs at every iteration\n",
    "    train_summary_writer.add_summary(summary,i)\n",
    "    if i % 100 == 0:        \n",
    "        #success ?\n",
    "        ta,tc = sess.run([accuracy,cross_entropy],feed_dict=train_data)\n",
    "        test_data = {X: mnist.test.images, Y_: mnist.test.labels}\n",
    "        va,vc,summary_test = sess.run([accuracy,cross_entropy,summary_op],feed_dict=test_data)\n",
    "        test_summary_writer.add_summary(summary_test,i)\n",
    "        print(\"Step : %d Batch : acc = %.4f loss = %.4f | Test acc = %.4f loss = %.4f\" % (i,ta,tc,va,vc))\n",
    "        \n",
    "    #--- edit\n",
    "#success on test data?\n",
    "test_data = {X: mnist.test.images, Y_: mnist.test.labels}\n",
    "a,c = sess.run([accuracy, cross_entropy], feed_dict=test_data)\n",
    "print(\"Test data acc = %.4f loss = %.4f\" % (a,c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Test image size\")\n",
    "print(mnist.test.images.shape)\n",
    "\n",
    "im_test = mnist.test.images[0].reshape([28,28])\n",
    "plt.imshow(im_test, cmap= cm.Greys)\n",
    "plt.show()\n",
    "#feed test again. By interactive sess we can use eval without sess !! easy!?\n",
    "res = Y.eval(feed_dict = test_data)\n",
    "print(\"Result size : \")\n",
    "print(res.shape)\n",
    "print(\"Picking up first response \")\n",
    "print(res[0])\n",
    "print(\"Softmax percentage : \")\n",
    "print(tf.nn.softmax(res[0]).eval())\n",
    "print(\"Result are : %d\" % np.argmax(res[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wts = W1.eval()\n",
    "wts.shape\n",
    "for i in range(0,10):\n",
    "    im = wts.flatten()[i::512].reshape((28,-1))\n",
    "    plt.imshow(im, cmap = cm.Greys)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wts = W2.eval()\n",
    "im = wts.flatten()[i::10].reshape([16,32])\n",
    "plt.imshow(im, cmap = cm.Greys)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow 3",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
